{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lighthouse Labs\n",
    "### W10D2 Recommendation Engines II\n",
    "\n",
    "July 27, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Agenda:**\n",
    "- Content-based Recommender Systems\n",
    "    - Item-to-item\n",
    "    - user-to-user\n",
    "    - Latent factors;\n",
    "    \n",
    "- Pros and Cons of different approaches to Recommenders\n",
    "- Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recommendation Systems\n",
    "\n",
    "- Two entities: **users** and **items**; \n",
    "    - whatever items may be: movies, books, musics, people, etc...;\n",
    "\n",
    "\n",
    "\n",
    "- Utility matrix: a matrix that captures the interaction between users and items; \n",
    "    - ratings, clicks, reviews, purchases;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ratings | Notting Hill | Jurassic Park | Rocky Balboa IV | Bird Box | Inglorious Basterds\n",
    "--------|--------------|---------------|-----------------|----------|----------------------\n",
    "User 1  |      ?       |      ?        |       2         |    ?     |    3 \n",
    "User 2  |      3       |      ?        |       ?         |    ?     |    ?\n",
    "User 3  |      ?       |      4        |       5         |    ?     |    5\n",
    "User 4  |      ?       |      ?        |       ?         |    ?     |    ?\n",
    "User 5  |      ?       |      ?        |       ?         |    5     |    ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Our main problem: _Sparsity_\n",
    "\n",
    "- The thing is: we cannot expect that users will interact with most items;\n",
    "    - Nobody has watched the whole (or the vast majority of the) catalogue of Netflix videos;\n",
    "        - Hopefully!\n",
    "    - Clients don't buy the majority of items in Amazon;\n",
    "    - Users don't listen to all the music in Spotify;\n",
    "    \n",
    "\n",
    "- Hence, the utility matrix usually has tons of missing data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What do we want?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Do we want to predict the missing ratings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Or do we want to find items that the users will enjoy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Aren't these problems equivalent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - We must carefully consider what we want, so we can properly train our model!\n",
    "     - but yes, our job for now is to try to fill **some** of the missing data in this matrix;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- There are different approaches to do so (which you learned yesterday): \n",
    "    - Content-based recommendations\n",
    "    - Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Content-based recommendation (Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use knowledge of each item to recommend a similar one (item-based recommendation)\n",
    "\n",
    "- Based on the features of the items and users. For example\n",
    "    - movies: drama, comedy, horror, actors, director\n",
    "    - books: math, languages, author, year, etc...\n",
    "    - destinations: temperature, coast, mountains, price, distance, etc...\n",
    "    - users: age, location, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If you read specific articles.\n",
    "* The representations of these articles as vectors will be similar to some other article representations as vectors.\n",
    "* A measure like cosine similarity is used to find similar articles.\n",
    "* These similar articles are then recommended to you if you haven’t read them to improve your engagement with the website or article medium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![img](img/CBF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Advantages\n",
    "\n",
    "- You don't need a lot of users to train your model.\n",
    "\n",
    "\n",
    "- Each user is modeled separately, so you might be able to capture uniqueness of taste.\n",
    "\n",
    "\n",
    "- Since you can obtain the features of the items, you can immediately recommend new items.\n",
    "\n",
    "\n",
    "- You can explain to the users why you are recommending an item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Disadvantages\n",
    "\n",
    "- Feature acquisition:\n",
    "    - What features should you use to explain the different ratings?\n",
    "    - Obtaining those features for each item might be very expensive. \n",
    "       <br>  <br>\n",
    "- Low diversity: hardly recommend an item outside the user's profile.\n",
    "    - What if a user has an eclectic taste?\n",
    " <br>  <br>\n",
    "- Cold start: you don't have any information about new users, what to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Collaborative Filtering: Memory Based Approach\n",
    "- User-user\n",
    "- Item-item\n",
    "- Latent-factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Memory-based collaborative filtering computes similarities between users or items and predicts a new rating for an item by taking the weighted average of ratings from the similar group. \n",
    "<br><br>\n",
    "\n",
    "- Use knowledge of a user’s past selections to recommend what similar users did (user-based recommendation).\n",
    "<br><br>\n",
    "- For item-based filtering: “users who preferred a certain item also liked…”\n",
    "<br><br>\n",
    "- The recommendations will be based on the utility matrix.\n",
    "<br><br>\n",
    "- The idea is to find similar items or similar users to make your recommendations, hence collaborative.\n",
    "    - Symmetry: movies are features to users and users are features to movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ratings | Notting Hill | Jurassic Park | Rocky Balboa IV | Bird Box | Inglorious Basterds\n",
    "--------|--------------|---------------|-----------------|----------|----------------------\n",
    "User 1  |      ?       |      ?        |       2         |    ?     |    3 \n",
    "User 2  |      3       |      ?        |       ?         |    ?     |    ?\n",
    "User 3  |      ?       |      4        |       5         |    ?     |    5\n",
    "User 4  |      ?       |      ?        |       ?         |    ?     |    ?\n",
    "User 5  |      ?       |      ?        |       ?         |    5     |    ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### User-to-user\n",
    "\n",
    "User-based filtering first selects a user and finds users who have similar rating patterns. The recommender system then can suggest items that those similar users liked.\n",
    "\n",
    "* The process is to calculate the similarities between target user i and all other users, select the top X similar users, and take the weighted average of ratings from these X users with similarities as weights.\n",
    "<br><br>\n",
    "* While different people may have different baselines when giving ratings, some people tend to give high scores generally, some are pretty strict even though they are satisfied with items. To avoid this bias, we can subtract each user’s average rating of all items when computing weighted average, and add it back for target user.\n",
    "\n",
    "\n",
    "- Suppose you want to predict the rating that Sophie would give to Shrek.\n",
    "\n",
    "- Here is one approach:\n",
    "    1. Calculate the similarity of Sophie with each one of the users.\n",
    "    3. Next, select the $k$ users that are most similar to Sophie and also rated Shrek.\n",
    "    2. Aggregate their ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Item-to-item\n",
    "\n",
    "- Item-based filtering takes an item first and finds users who liked the particular item, then searches other items that those users also liked.\n",
    "\n",
    "- Item based collaborative filtering was introduced 1998 by Amazon. \n",
    "\n",
    "- Item based filtering looks at the similarity between different items, and does this by taking note of how many users that chose item X also chose item Y. \n",
    "\n",
    "- If the correlation is high enough, a similarity can be presumed to exist between the two items, and they can be assumed to be similar to one another.\n",
    "\n",
    "* E.g. Suppose you want to predict the rating that a user (Sophie) would give to a movie (Shrek)\n",
    "\n",
    "\n",
    "- Here is one approach:\n",
    "    1. Calculate the similarity between Shrek and each one of the movies in our matrix.\n",
    "    2. Next, select the $k$ movies that are  most similar to Shrek and that were also rated by Sophie.\n",
    "    3. Aggregate these ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating your recommender system (discussion)\n",
    "\n",
    "- Assessment of a recommender system can be very tricky;\n",
    "\n",
    "\n",
    "- Well, we can use the classical measures: mean squared error, mean absolute error;\n",
    "\n",
    "\n",
    "- But these error measures might be misleading;\n",
    "\n",
    "\n",
    "- What we actually want to measure is the interest that our user have on the recommended items;\n",
    "\n",
    "\n",
    "- Maybe [we can blame Netflix for this](https://en.wikipedia.org/wiki/Netflix_Prize)!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Remember that:\n",
    "\n",
    "- Just training your model and evaluating it offline is not ideal.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "- We don't have a ground truth! \n",
    "\n",
    "\n",
    "- Although we want to recommend only items the user is interested in, the recommended items might skew/affect the users interest;\n",
    "    - we can't measure this offline;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Because of this, one can argue that the best way of testing a recommender system is actually testing it for real (A/B test). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Besides...\n",
    "\n",
    "- The fact that a user liked a movie, it doesn't mean he/she wants to watch a similar movie in sequence;\n",
    "    - also hard to capture this offline;\n",
    "\n",
    "\n",
    "- Suppose a user likes action and sci-fi movies. \n",
    "\n",
    "\n",
    "- After just watching an action movie, should we recommend similar action movies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Diversity**: Our user is a Harry Potter fan, should we recommend HP1, HP2, HP3,...? We might want some diversity! To measure diversity you could user, for example,\n",
    "$$\n",
    "1 - \\bar{S}\n",
    "$$\n",
    "where $\\bar{S}$ is the average similarity of your recommendations; \n",
    "    - Careful though, you need a balance. Just going for diversity is pointless;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Novelty:** You want to indicate new items to your users or the most popular items? We need a balance here\n",
    "    - Just going for popular items won't surprise your users;\n",
    "    - Just going for new/unknown items affects the trust in your recommendation;\n",
    "        - Besides, popular items are popular for a reason;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Responsiveness:** how fast does your system change as new user/items interactions arrive? \n",
    "    - In other words, how frequently should you update your utility matrix?\n",
    "    \n",
    "    \n",
    "- **Persistence:** How long do you want to keep an item in your recommended list?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-algorithmic recommendations bias\n",
    "\n",
    "- There might be other reasons for you to recommend items;\n",
    "\n",
    "\n",
    "- For example, Netflix might want to stimulate original productions;\n",
    "\n",
    "\n",
    "- A company might want to favor a product with high profit margin;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Or you might want not recommend somethings\n",
    "\n",
    "- [Is Target the new pregnancy test?](https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/#4d7f597f6668)\n",
    "<br><br>\n",
    "- [Walmart links Martin Luther King Jr. to “Planet of the Apes”](http://www.nbcnews.com/id/10730202/ns/technology_and_science-tech_and_gadgets/t/wal-mart-blames-human-error-offensive-link/#.XEamRc2IaUk)\n",
    "<br><br>\n",
    "- BE CAREFUL WITH SENSITIVE MATTERS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of data\n",
    "\n",
    "- Explicit data: ratings, thumbs up, etc...\n",
    "\n",
    "\n",
    "- Implicit data: collected from your behaviour (e.g., mouse clicks, purchases, time spent doing something)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Users don't like to give explicit data\n",
    "    - so companies use different strategies: (tag your photo, 10 years challenge?)\n",
    "        - it is nice for you, so you do it;\n",
    "        - but it is also nice for them;\n",
    "        - Using these things without you knowing, is that ethical?\n",
    "        \n",
    "\n",
    "\n",
    "- trust more implicit data that costs something, like time or even money;\n",
    "    - this makes it harder to fraud;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Based Collaborative Filtering\n",
    "\n",
    "Our task: decreases the dimension of the utility matrix A by extracting its latent factors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Latent factors\n",
    "- Latent factors are the characteristics of the items, for example, the genre of the music, the genre of the movie... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example of Matrix Factorization using PCA \n",
    "\n",
    "![img](img/0_pca.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are going to do this using `Matrix Factorization` reducing the `Movie Ratings Matrix` into `Movies` and `Users Matrix`.\n",
    "\n",
    "These Matrices will be dense representations of the Movie Ratings Matrix.\n",
    "\n",
    "\n",
    "![img](img/SVD01.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How our data looks like?\n",
    "\n",
    "![img](img/SVD03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We've seen that if we had the user profile, we can learn the movie profile $\\hat{X}$ \n",
    "\n",
    "- Or if we had the movie profile, we could learn the user profile $\\hat{\\beta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We have a similar problem, but instead of minimizing on either $X$ or $\\beta$, we need to minimize on both!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "L(y_{ij}, \\hat{y}_{ij}) = \\sum_{i,j}u_{ij}\\left(y_{ij} -  X^{(j)}\\left(\\beta^{(i)}\\right)\\right)^2 + \\lambda||\\beta||^2+ \\lambda||X||^2\n",
    "$$\n",
    "where $u_{ij}=1$ if User $i$ has provided a rating for movie $j$, and 0 otherwise;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let $Y$ be our utility matrix, then we can write $Y$ like\n",
    "$$\n",
    "Y^T \\approx \\hat{X}_{(n\\times k)}\\hat{\\beta}_{(k\\times m)}\n",
    "$$\n",
    "for some $k<m$;\n",
    "\n",
    "<br>\n",
    "- So what is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SVD\n",
    "\n",
    "* The Singular Value Decomposition (SVD) decreases the dimension of the utility matrix A by extracting its latent factors\n",
    "<br><br>\n",
    "\n",
    "**WARNING:** This is not SVD in reality.\n",
    "* Actual SVD works on filled data in matrices like PCA does.\n",
    "* This algorithm is inspired from SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Standard matrix factorization approaches won't work because of the missing values.\n",
    "\n",
    "- We'll estimate matrix factorization using an iterative algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Estimating a Matrix Factorization\n",
    "\n",
    "1. Set all elements in your User and Movie matrices to random numbers.\n",
    "$$\\hat{X}_{(n\\times k)}\\hat{\\beta}_{(k\\times m)}$$\n",
    "\n",
    "<br><br>\n",
    "$\\hat{X}_{(n\\times k)}\\hat{\\beta}_{(k\\times m)}$ will result in random numbers\n",
    "\n",
    "2. Create a \"cost function\" that checks how far off $\\hat{X}_{(n\\times k)}\\hat{\\beta}_{(k\\times m)}$ currently is from equaling the known values of the Movie Rating matrix.\n",
    "\n",
    "3. Using a numerical optimization algorithm, tweak the numbers in your matrices a little at a time; the goal is to get your \"cost function\" closer to zero.\n",
    "\n",
    "4. Repeat until we can't reduce the cost function any more.\n",
    "\n",
    "$$\n",
    "Y^T \\approx \\hat{X}_{(n\\times k)}\\hat{\\beta}_{(k\\times m)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### OK we factorized $Y$, so what?\n",
    "\n",
    "- Now you have your movie features $\\hat{X}$ and your users features $\\hat{\\beta}$;\n",
    "\n",
    "\n",
    "- Well, again, there's no recipe. You can use different approaches;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- One possible approach is to just estimate the missing entries in a row, and recommend the ones with highest ratings to the user;\n",
    "\n",
    "\n",
    "- Another approach is to use the learned movie features to find movies that are similar to a specific movie:\n",
    "    - \"because you watched Jurassic Park: \"\n",
    "\n",
    "\n",
    "- Or we can apply ML techniques: K-Means, KNN, the choice is yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visual SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Each movies has different genres like comedy and action with a specified rating precalculated.\n",
    "\n",
    "User also has a preference for these genres like ‘I like comedy or I dislike it’. Only the like score is added into the rating.\n",
    "\n",
    "![img](img/SVD04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We get a final rating matrix like so.\n",
    "\n",
    "Basically, the right matrix can be factorized into the 2 left matrices\n",
    "\n",
    "![img](img/SVD05.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need to get target matrix on right decomposed into 2 matrices\n",
    "We need to find 2 matrices which when multiplied give us the target matrix\n",
    "How do we do this?\n",
    "\n",
    "![img](img/SVD06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We get a final rating matrix like so.\n",
    "\n",
    "Basically, the right matrix can be factorized into the 2 left matrices\n",
    "\n",
    "We start with random matrices and use gradient descent to find right values to get the correct target matrix\n",
    "\n",
    "![img](img/SVD07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see we get 1.44 instead of 3\n",
    "This needs to be corrected.\n",
    "![img](img/SVD08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gradient descent will update values in the non target matrices.\n",
    "With enough iterations we will reach the right values.\n",
    "\n",
    "![img](img/SVD09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/SVD10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Same technique can be used to factorize empty target matrices as well.\n",
    "Thus we get right factored matrices from random ones.\n",
    "When multiplied these give ratings for all users.\n",
    "![img](img/SVD11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Truncated SVD Demo\n",
    "\n",
    "Performs linear dimensionality reduction by means of truncated singular value decomposition (SVD).  \n",
    "This estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Missing values means matrix decomposition cannot happen naturally.\n",
    "We thus use Machine Learning iterative approach to complete the missing values.\n",
    "The filled values which are ratings for users if high, those movies can be recommended to a user.\n",
    "\n",
    "Actual SVD works on filled data in matrices like PCA does. We are going to use Truncated SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix as sparse_matrix\n",
    "import os\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings = pd.read_csv('data/ratings.csv')\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "movieId                                       \n",
       "1                          Toy Story (1995)   \n",
       "2                            Jumanji (1995)   \n",
       "3                   Grumpier Old Men (1995)   \n",
       "4                  Waiting to Exhale (1995)   \n",
       "5        Father of the Bride Part II (1995)   \n",
       "\n",
       "                                              genres  \n",
       "movieId                                               \n",
       "1        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2                         Adventure|Children|Fantasy  \n",
       "3                                     Comedy|Romance  \n",
       "4                               Comedy|Drama|Romance  \n",
       "5                                             Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# to look up titles\n",
    "movie_info = pd.read_csv('data/movies.csv', index_col=0)\n",
    "movie_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_stats(ratings, item_key=\"item\", user_key=\"user\"):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"The average rating:\", np.mean(ratings[\"rating\"]))\n",
    "\n",
    "    n = len(set(ratings[item_key]))\n",
    "    d = len(set(ratings[user_key]))\n",
    "    print(\"Number of users:\", d)\n",
    "    #print(\"Number of items:\", n)\n",
    "    print(\"Fraction nonzero:\", len(ratings)/(n*d))\n",
    "    print(\"Size of full X matrix (GB):\", (n*d)*8/1e9)\n",
    "\n",
    "    return n,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def create_X(ratings, n, d, user_key=\"user\", item_key=\"item\"):\n",
    "    \"\"\"\n",
    "    Creates a sparse matrix using scipy.csr_matrix and mappers to relate indexes to items' id.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ratings: the ratings to be stored in the matrix;\n",
    "    n: the number of items\n",
    "    d: the number of users\n",
    "    user_key: the column in the pandas dataframe that contains the users id\n",
    "    item_key: the column in the pandas dataframe that contains the items id\n",
    "    \n",
    "    Returns: (X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind)\n",
    "    --------\n",
    "    X: the sparse matrix containing the ratings. Note that\n",
    "    user_mapper: stores the indexes of the users - the user_id is the key;\n",
    "    item_mapper: stores the indexes of the items - the item_id is the key;\n",
    "    user_inverse_mapper: stores the user id - the user index is the key;\n",
    "    item_inverse_mapper: stores the item id - the item index is the key;\n",
    "    user_ind: indexes of the users;\n",
    "    item_ind: indexes of the items;\n",
    "    \"\"\"\n",
    "    \n",
    "    user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(d))))\n",
    "    item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(n))))\n",
    "\n",
    "    user_inverse_mapper = dict(zip(list(range(d)), np.unique(ratings[user_key])))\n",
    "    item_inverse_mapper = dict(zip(list(range(n)), np.unique(ratings[item_key])))\n",
    "\n",
    "    user_ind = [user_mapper[i] for i in ratings[user_key]]\n",
    "    item_ind = [item_mapper[i] for i in ratings[item_key]]\n",
    "\n",
    "    X = sparse_matrix((ratings[\"rating\"], (item_ind, user_ind)), shape=(n,d))\n",
    "    \n",
    "    return X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def find_nearestneighbour(model, X, query_ind):\n",
    "    \n",
    "    model.fit(X)\n",
    "    if X[query_ind].ndim==2:\n",
    "        neighbors_idx = model.kneighbors(X[query_ind], return_distance=False).ravel()\n",
    "    else: \n",
    "        neighbors_idx = model.kneighbors(X[query_ind][None], return_distance=False).ravel()\n",
    "    \n",
    "    return np.delete(neighbors_idx, np.where(neighbors_idx==query_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def print_movie_pop(nn):\n",
    "    movies = [movie_inverse_mapper[z] for z in nn]\n",
    "    pop = np.sum(movie_X[nn], axis=1) \n",
    "    for i in range(0,5):\n",
    "        print(f\"\\t{movie_info.loc[movies[i],'title']:50} Total stars: {pop[i,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 100836\n",
      "The average rating: 3.501556983616962\n",
      "Number of users: 610\n",
      "Fraction nonzero: 0.016999683055613623\n",
      "Size of full X matrix (GB): 0.04745312\n"
     ]
    }
   ],
   "source": [
    "movie_n, movie_d = get_stats(movie_ratings, user_key=\"userId\", item_key=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "movie_X, user_mapper, movie_mapper, user_inverse_mapper, movie_inverse_mapper, user_ind, movie_ind = create_X(movie_ratings, movie_n, movie_d, user_key=\"userId\", item_key=\"movieId\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2353,  546,  615, 1756,  622])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_euc = find_nearestneighbour(NearestNeighbors(n_neighbors=6), movie_X, 0)\n",
    "nn_euc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "toy_story_ind = 0\n",
    "toy_story_vec = movie_X[toy_story_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "SVD(k=10): \n",
      "\tIndependence Day (a.k.a. ID4) (1996)               Total stars: 696.0\n",
      "\tBack to the Future (1985)                          Total stars: 690.5\n",
      "\tJurassic Park (1993)                               Total stars: 892.5\n",
      "\tAladdin (1992)                                     Total stars: 694.0\n",
      "\tGroundhog Day (1993)                               Total stars: 564.0\n",
      "\n",
      "\n",
      "\n",
      "SVD(k=100): \n",
      "\tToy Story 2 (1999)                                 Total stars: 374.5\n",
      "\tMission: Impossible (1996)                         Total stars: 573.0\n",
      "\tIndependence Day (a.k.a. ID4) (1996)               Total stars: 696.0\n",
      "\tWilly Wonka & the Chocolate Factory (1971)         Total stars: 461.0\n",
      "\tBabe (1995)                                        Total stars: 467.5\n",
      "\n",
      "\n",
      "\n",
      "SVD(k=500): \n",
      "\tToy Story 2 (1999)                                 Total stars: 374.5\n",
      "\tMission: Impossible (1996)                         Total stars: 573.0\n",
      "\tIndependence Day (a.k.a. ID4) (1996)               Total stars: 696.0\n",
      "\tBug's Life, A (1998)                               Total stars: 323.5\n",
      "\tNutty Professor, The (1996)                        Total stars: 224.0\n",
      "\n",
      "\n",
      " Euclidean:\n",
      "\tToy Story 2 (1999)                                 Total stars: 374.5\n",
      "\tMission: Impossible (1996)                         Total stars: 573.0\n",
      "\tIndependence Day (a.k.a. ID4) (1996)               Total stars: 696.0\n",
      "\tBug's Life, A (1998)                               Total stars: 323.5\n",
      "\tNutty Professor, The (1996)                        Total stars: 224.0\n"
     ]
    }
   ],
   "source": [
    "for k in [10, 100, 500]:\n",
    "    print(\"\\n\\n\")\n",
    "    movie_svd = TruncatedSVD(n_components=k)\n",
    "    Z = movie_svd.fit_transform(movie_X)\n",
    "    nn_svd = find_nearestneighbour(NearestNeighbors(n_neighbors=50), Z, 0)\n",
    "\n",
    "    print(f\"SVD(k={k}): \")\n",
    "    print_movie_pop(nn_svd) \n",
    "    \n",
    "print(\"\\n\\n Euclidean:\")\n",
    "print_movie_pop(nn_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
